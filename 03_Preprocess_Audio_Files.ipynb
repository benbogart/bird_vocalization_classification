{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coastal-convert",
   "metadata": {},
   "source": [
    "# Preprocess Audio Files\n",
    "This notebook contains the code for preprocessing the audio files before training.\n",
    "\n",
    "10 second audio in wav format with a sample rate of 48k was chosen because it matches the audio used to train the l3 model from which I plan to use for feature embeddings.\n",
    "\n",
    "The sample dataset only includes the training data, so we will split that into training and testing data.  If the mode proves viable we will download more data from xeno-canto.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "narrative-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sox # must install sox locally if you want mp3 support\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = 'data/train_audio'\n",
    "EXTRA_DATA_DIR = 'data/xeno-canto/'\n",
    "OUTPUT_DIR = 'data/audio_10sec'\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# create output dir if it does not exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/train_audio/olsfly/XC386256.mp3',\n",
       "  'data/train_audio/olsfly/XC484154.mp3',\n",
       "  'data/train_audio/olsfly/XC239498.mp3',\n",
       "  'data/train_audio/olsfly/XC368006.mp3',\n",
       "  'data/train_audio/olsfly/XC156193.mp3'],\n",
       " ['data/xeno-canto/XC76626.mp3',\n",
       "  'data/xeno-canto/XC441588.mp3',\n",
       "  'data/xeno-canto/XC368433.mp3',\n",
       "  'data/xeno-canto/XC146762.mp3',\n",
       "  'data/xeno-canto/XC627879.mp3'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all mp3 files\n",
    "\n",
    "# from original dataset\n",
    "audio_files = glob(os.path.join(ORIGINAL_DATA_DIR, '*/*.mp3'))\n",
    "\n",
    "# from additional downloaded data from xeno-canto.com\n",
    "audio_files += glob(os.path.join(EXTRA_DATA_DIR, '*.mp3'))\n",
    "\n",
    "audio_files[:5], audio_files[-5:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "worst-father",
   "metadata": {},
   "source": [
    "# get the unique class names of the birds in our training set\n",
    "df = pd.read_csv('data/train.csv')\n",
    "classes = sorted(df['ebird_code'].unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "vietnamese-watts",
   "metadata": {},
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-translator",
   "metadata": {},
   "source": [
    "# Convert files to 10 second WAV / downsample to `SAMPLE_RATE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-reggae",
   "metadata": {},
   "source": [
    "The audio files have to be processed in two steps because adding padding to an mp3 then saving as wav results in imprecise final times.  We need files to be exactly 10 seconds long wtih a sample rate of 48khz for a total of `SAMPLE_RATE` * 10 samples.\n",
    "\n",
    "The first pass resamples the audio to `SAMPLE_RATE`, cuts the clips to 11 seconds, and saves as wav files.\n",
    "\n",
    "The second pass pads or crops the files to exactly 10 seconds long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "micro-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# get the number of cpu cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(af):\n",
    "    \n",
    "    # generate filenames\n",
    "    wav_name = os.path.splitext(os.path.basename(af))[0] + '.wav'\n",
    "    class_name = af.split('/')[-2]\n",
    "    outfile = os.path.join(OUTPUT_DIR, wav_name)\n",
    "    \n",
    "    # only convert if we haven't already\n",
    "    if(not os.path.exists(outfile)):\n",
    "        \n",
    "        # use sox to convert\n",
    "        tfm = sox.Transformer()\n",
    "        \n",
    "        # use 11 seconds because the conversion is imprecise\n",
    "        tfm.trim(start_time=0.0, end_time=11.0)\n",
    "        tfm.convert(samplerate=SAMPLE_RATE, \n",
    "                    n_channels=1, \n",
    "                    bitdepth= 16)\n",
    "        \n",
    "        # convert\n",
    "        try:\n",
    "            tfm.build(input_filepath=af, output_filepath=outfile)    \n",
    "        except:\n",
    "            print(f'There was a Sox error on {af}.  The file was not processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prompt-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 61283 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 61283 out of 61283 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Process the conversion using all cores in parallel to save time\n",
    "print(f'Starting to process {len(audio_files)} files')\n",
    "_ = Parallel(n_jobs=num_cores, verbose=1)(delayed(convert_to_wav)(i) for i in audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "august-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/audio_10sec/XC174211.wav',\n",
       " 'data/audio_10sec/XC454444.wav',\n",
       " 'data/audio_10sec/XC334841.wav',\n",
       " 'data/audio_10sec/XC103099.wav',\n",
       " 'data/audio_10sec/XC172660.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all the .wav files\n",
    "wav_audio_files = glob(os.path.join(OUTPUT_DIR, '*.wav'), recursive=True)\n",
    "wav_audio_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "shared-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_pad_audio(af):\n",
    "\n",
    "    # get file duration\n",
    "    duration = sox.file_info.duration(af)\n",
    "    \n",
    "    # generate filename\n",
    "    basename = os.path.basename(af)\n",
    "    class_name = af.split('/')[-2]\n",
    "    outfile = os.path.join(OUTPUT_DIR, basename)    \n",
    "\n",
    "    # Check for no lengh error\n",
    "    if duration == None:\n",
    "        print('duration is None:', af)\n",
    "    elif duration < 10.0:\n",
    "        # crop long files\n",
    "        # move file to pwd\n",
    "        os.rename(af, basename)\n",
    "        \n",
    "        # setup transformer\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.pad(start_duration=0.0, end_duration=(10.0 - duration))\n",
    "        \n",
    "        # convert\n",
    "        tfm.build(input_filepath=basename, output_filepath=outfile)\n",
    "\n",
    "        # remove the old file\n",
    "        os.remove(basename)        \n",
    "\n",
    "    elif duration > 10.0:\n",
    "        # pad short files\n",
    "        \n",
    "        # first move the working file to pwd\n",
    "        os.rename(af, basename)\n",
    "        \n",
    "        # setup transformer\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.trim(start_time=0.0, end_time=10.0)\n",
    "        \n",
    "        # convert\n",
    "        tfm.build(input_filepath=basename, output_filepath=outfile)\n",
    "\n",
    "        # remove the old file\n",
    "        os.remove(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extensive-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 61283 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 200 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 1400 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done 3400 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done 6200 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 9800 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 14200 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 19400 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 25400 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 32200 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 39800 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 48200 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 57400 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=4)]: Done 61283 out of 61283 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "print(f'Starting to process {len(wav_audio_files)} files')\n",
    "_ = Parallel(n_jobs=num_cores, verbose=1)(delayed(crop_pad_audio)(i) for i in wav_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sharing-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 61283 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done 1576 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=4)]: Done 2476 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 4876 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 6376 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 8076 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 9976 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 12076 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=4)]: Done 14376 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 16876 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 19576 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 22476 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 25576 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=4)]: Done 28876 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 32376 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=4)]: Done 36076 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done 39976 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=4)]: Done 44076 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=4)]: Done 48376 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=4)]: Done 52876 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done 57576 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=4)]: Done 61276 out of 61283 | elapsed: 18.0min remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 61283 out of 61283 | elapsed: 18.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# Make sure all the files are exatcly 10 seconds long\n",
    "\n",
    "def check_length(pf):\n",
    "    duration = sox.file_info.duration(pf)\n",
    "    sr = sox.file_info.sample_rate(pf)\n",
    "    if duration != 10.0  or sr != SAMPLE_RATE:\n",
    "        return (duration, \n",
    "                sox.file_info.sample_rate(pf),\n",
    "                sox.file_info.bitrate(pf),\n",
    "                pf)\n",
    "    channels = sox.file_info.channels(pf)\n",
    "    if channels != 1:\n",
    "        return (channels, pf)\n",
    "    return False\n",
    "\n",
    "print(f'Starting to process {len(wav_audio_files)} files')\n",
    "errors = Parallel(n_jobs=num_cores, verbose=1)(delayed(check_length)(i) for i in wav_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cooked-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files were 10.0 seconds long.  Ready to move on.\n"
     ]
    }
   ],
   "source": [
    "# count errors\n",
    "def count_errors(errors):\n",
    "    filtered_errors = [x for x in errors if x]\n",
    "\n",
    "    if len(filtered_errors) > 0:\n",
    "        print('There were errors')\n",
    "        print(filtered_errors)\n",
    "    else:\n",
    "        print('All files were 10.0 seconds long.  Ready to move on.')\n",
    "        \n",
    "count_errors(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-collection",
   "metadata": {},
   "source": [
    "# Create Full Length npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "obvious-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ouput directory\n",
    "OUTPUT_DIR_NPY = 'data/npy'\n",
    "os.makedirs(OUTPUT_DIR_NPY, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "republican-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_npy(af):\n",
    "    \n",
    "    # generate output filename\n",
    "    npy_name = os.path.splitext(os.path.basename(af))[0] + '.npy'\n",
    "    outfile = os.path.join(OUTPUT_DIR_NPY, npy_name)\n",
    "\n",
    "    # convert the audio file to npy\n",
    "    if not os.path.exists(outfile):\n",
    "        try:\n",
    "            signal, sr = librosa.load(af, sr=22050, mono=True)\n",
    "            np.save(outfile, signal)\n",
    "        except:\n",
    "            # return filename if there is an error\n",
    "            return af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "global-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 61283 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 61283 out of 61283 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "print(f'Starting to process {len(audio_files)} files')\n",
    "errors = Parallel(n_jobs=num_cores, verbose=1)(delayed(convert_to_npy)(af) for af in audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instructional-vertical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list errors\n",
    "[e for e in errors if e != None]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio-ml]",
   "language": "python",
   "name": "conda-env-audio-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
