{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coastal-convert",
   "metadata": {},
   "source": [
    "# Preprocess Audio Files\n",
    "This notebook contains the code for preprocessing the audio files before training.\n",
    "\n",
    "10 second audio in wav format with a sample rate of 48k was chosen because it matches the audio used to train the l3 model from which I plan to use for feature embeddings.\n",
    "\n",
    "The sample dataset only includes the training data, so we will split that into training and testing data.  If the mode proves viable we will download more data from xeno-canto.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "narrative-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sox # must install sox locally if you want mp3 support\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = 'data/train_audio'\n",
    "EXTRA_DATA_DIR = 'data/xeno-canto/'\n",
    "OUTPUT_DIR = 'data/audio_10sec'\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# create output dir if it does not exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dressed-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/train_audio/olsfly/XC386256.mp3',\n",
       "  'data/train_audio/olsfly/XC484154.mp3',\n",
       "  'data/train_audio/olsfly/XC239498.mp3',\n",
       "  'data/train_audio/olsfly/XC368006.mp3',\n",
       "  'data/train_audio/olsfly/XC156193.mp3'],\n",
       " ['data/xeno-canto/XC76626.mp3',\n",
       "  'data/xeno-canto/XC441588.mp3',\n",
       "  'data/xeno-canto/XC368433.mp3',\n",
       "  'data/xeno-canto/XC146762.mp3',\n",
       "  'data/xeno-canto/XC627879.mp3'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all mp3 files\n",
    "\n",
    "# from original dataset\n",
    "audio_files = glob(os.path.join(ORIGINAL_DATA_DIR, '*/*.mp3'))\n",
    "\n",
    "# from additional downloaded data from xeno-canto.com\n",
    "audio_files += glob(os.path.join(EXTRA_DATA_DIR, '*.mp3'))\n",
    "\n",
    "audio_files[:5], audio_files[-5:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "worst-father",
   "metadata": {},
   "source": [
    "# get the unique class names of the birds in our training set\n",
    "df = pd.read_csv('data/train.csv')\n",
    "classes = sorted(df['ebird_code'].unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "vietnamese-watts",
   "metadata": {},
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-translator",
   "metadata": {},
   "source": [
    "# Convert files to 10 second WAV / downsample to `SAMPLE_RATE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-reggae",
   "metadata": {},
   "source": [
    "The audio files have to be processed in two steps because adding padding to an mp3 then saving as wav results in imprecise final times.  We need files to be exactly 10 seconds long wtih a sample rate of 48khz for a total of `SAMPLE_RATE` * 10 samples.\n",
    "\n",
    "The first pass resamples the audio to `SAMPLE_RATE`, cuts the clips to 11 seconds, and saves as wav files.\n",
    "\n",
    "The second pass pads or crops the files to exactly 10 seconds long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "micro-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# get the number of cpu cores available\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decreased-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governing-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(af):\n",
    "        \n",
    "    wav_name = os.path.splitext(os.path.basename(af))[0] + '.wav'\n",
    "    class_name = af.split('/')[-2]\n",
    "    outfile = os.path.join(OUTPUT_DIR, wav_name)\n",
    "    \n",
    "    if(not os.path.exists(outfile)):\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.trim(start_time=0.0, end_time=11.0)\n",
    "        tfm.convert(samplerate=SAMPLE_RATE, \n",
    "                    n_channels=1, \n",
    "                    bitdepth= 16)\n",
    "        tfm.build(input_filepath=af, output_filepath=outfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prompt-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 49759 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done 355 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=3)]: Done 49759 out of 49759 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Process the conversion using all cores in parallel to save time\n",
    "print(f'Starting to process {len(audio_files)} files')\n",
    "_ = Parallel(n_jobs=num_cores, verbose=1)(delayed(convert_to_wav)(i) for i in audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "august-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/audio_10sec/XC174211.wav',\n",
       " 'data/audio_10sec/XC454444.wav',\n",
       " 'data/audio_10sec/XC334841.wav',\n",
       " 'data/audio_10sec/XC172660.wav',\n",
       " 'data/audio_10sec/XC134635.wav']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all the .wav files\n",
    "wav_audio_files = glob(os.path.join(OUTPUT_DIR, '*.wav'), recursive=True)\n",
    "wav_audio_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "shared-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_pad_audio(af):\n",
    "\n",
    "    duration = sox.file_info.duration(af) # gets duration in seconds\n",
    "    basename = os.path.basename(af)\n",
    "    class_name = af.split('/')[-2]\n",
    "    outfile = os.path.join(OUTPUT_DIR, basename)    \n",
    "\n",
    "    if duration == None:\n",
    "        print('duration is None:', af)\n",
    "    elif duration < 10.0:\n",
    "        # first move the working file to pwd\n",
    "        os.rename(af, basename)\n",
    "\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.pad(start_duration=0.0, end_duration=(10.0 - duration))\n",
    "        tfm.build(input_filepath=basename, output_filepath=outfile)\n",
    "\n",
    "        # remove the old file\n",
    "        os.remove(basename)        \n",
    "\n",
    "    elif duration > 10.0:\n",
    "        # first move the working file to pwd\n",
    "        os.rename(af, basename)\n",
    "\n",
    "        tfm = sox.Transformer()\n",
    "        tfm.trim(start_time=0.0, end_time=10.0)\n",
    "        tfm.build(input_filepath=basename, output_filepath=outfile)\n",
    "\n",
    "        # remove the old file\n",
    "        os.remove(basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "extensive-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 49745 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done 1345 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=3)]: Done 3345 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=3)]: Done 6145 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=3)]: Done 9745 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 14145 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=3)]: Done 19345 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=3)]: Done 25345 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=3)]: Done 32145 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=3)]: Done 39745 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=3)]: Done 48145 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=3)]: Done 49745 out of 49745 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "print(f'Starting to process {len(wav_audio_files)} files')\n",
    "_ = Parallel(n_jobs=num_cores, verbose=1)(delayed(crop_pad_audio)(i) for i in wav_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sharing-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 49745 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=3)]: Done 367 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=3)]: Done 867 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=3)]: Done 1567 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=3)]: Done 2467 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 3567 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 4867 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=3)]: Done 6367 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=3)]: Done 8067 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=3)]: Done 9967 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=3)]: Done 12067 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=3)]: Done 14367 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=3)]: Done 16867 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=3)]: Done 19567 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=3)]: Done 22467 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=3)]: Done 25567 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=3)]: Done 28867 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=3)]: Done 32367 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=3)]: Done 36067 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=3)]: Done 39967 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=3)]: Done 44067 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=3)]: Done 48367 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=3)]: Done 49745 out of 49745 | elapsed: 18.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# Make sure all the files are exatcly 10 seconds long\n",
    "\n",
    "def check_length(pf):\n",
    "    duration = sox.file_info.duration(pf)\n",
    "    sr = sox.file_info.sample_rate(pf)\n",
    "    if duration != 10.0  or sr != SAMPLE_RATE:\n",
    "        return (duration, \n",
    "                sox.file_info.sample_rate(pf),\n",
    "                sox.file_info.bitrate(pf),\n",
    "                pf)\n",
    "    channels = sox.file_info.channels(pf)\n",
    "    if channels != 1:\n",
    "        return (channels, pf)\n",
    "    return False\n",
    "\n",
    "print(f'Starting to process {len(wav_audio_files)} files')\n",
    "errors = Parallel(n_jobs=num_cores, verbose=1)(delayed(check_length)(i) for i in wav_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cooked-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were errors\n",
      "[(None, 22050.0, None, 'data/audio_10sec/XC109763.wav')]\n"
     ]
    }
   ],
   "source": [
    "# count errors\n",
    "filtered_errors = [x for x in errors if x]\n",
    "\n",
    "if len(filtered_errors) > 0:\n",
    "    print('There were errors')\n",
    "    print(filtered_errors)\n",
    "else:\n",
    "    print('All files were 10.0 seconds long.  Ready to move on.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-removal",
   "metadata": {},
   "source": [
    "# Save Mel-Spectrograms\n",
    "\n",
    "Here we are saving the Mel-Spectrograms with the best parameters from our model testing so that I can try using mixins to augment the data.  Mixins work on the image representation of the audio file and are calculated by the datagenerator so the Mel-Spectrogram must be completed prior to feeding the data into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excellent-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_dir = OUTPUT_DIR + '_mels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "uniform-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspec(af, n_ftt, hop_length, n_mels):  n_fft=2048, hop_length=512\n",
    "    mel_spec = librosa.feature.melspectrogram(data, sr=SAMPLE_RATE, n_fft=n_fft, \n",
    "                                       hop_length=hop_length, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    return mel_spec_dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(S_DB, sr=sample_rate, hop_length=hop_length, x_axis='time', y_axis='mel');\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decimal-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress mp3 warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='PySoundFile failed. Trying audioread instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "threaded-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/37503 [00:09<14:03:21,  1.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-fd6bb31cc257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     mel_spec = librosa.feature.melspectrogram(data, \n\u001b[0m\u001b[1;32m     12\u001b[0m                                               \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                               \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \"\"\"\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   1997\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2510\u001b[0m         S = (\n\u001b[1;32m   2511\u001b[0m             np.abs(\n\u001b[0;32m-> 2512\u001b[0;31m                 stft(\n\u001b[0m\u001b[1;32m   2513\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mbl_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         stft_matrix[:, bl_s:bl_t] = fft.rfft(\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mfft_window\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         )\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0minv_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# see if we can load 10 second clips to make mel spectrograms\n",
    "shapes = []\n",
    "\n",
    "# set from best model\n",
    "n_fft = 2048\n",
    "hop_length=512\n",
    "n_mels=128\n",
    "\n",
    "for file in tqdm(audio_files):\n",
    "    \n",
    "\n",
    "    data, sr = librosa.load(file, sr=SAMPLE_RATE, duration=10.0)\n",
    "    mel_spec = librosa.feature.melspectrogram(data, \n",
    "                                              sr=SAMPLE_RATE, \n",
    "                                              n_fft=n_fft, \n",
    "                                              hop_length=hop_length, \n",
    "                                              n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    shapes.append(mel_spec_db.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "conventional-clinton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All outputs are the same shape: True\n"
     ]
    }
   ],
   "source": [
    "print('All outputs are the same shape:', len(set(shapes)) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-portfolio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio-ml]",
   "language": "python",
   "name": "conda-env-audio-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
